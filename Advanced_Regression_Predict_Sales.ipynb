{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8587,
          "databundleVersionId": 868304,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Advanced Regression : Predict Sales",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "## **Why This Project?**\n",
        "This project is part of the \"How to Win a Data Science Competition\" Coursera course, and it presents a real-world challenge of predicting sales for one of Russia's largest software firms, 1C Company. Accurate sales forecasting is a critical aspect of retail operations, helping businesses optimize inventory, reduce overstock and understock situations, and improve customer satisfaction. The ability to predict future sales empowers businesses to plan better, minimize wastage, and maximize profits.\n",
        "\n",
        "In this competition, we are tasked with forecasting the total sales for each product in every store for the upcoming month. Given the dynamic nature of product availability, pricing fluctuations, and store-specific trends, this problem mirrors the complex forecasting issues faced by retail companies worldwide.\n",
        "\n",
        "## **Real-Life Problem Solved**\n",
        "Sales forecasting is a fundamental problem for any retail chain, as it directly impacts supply chain management, operational efficiency, and profitability. Retailers need to handle large volumes of sales data across numerous stores and products, all while accounting for seasonal variations, promotional periods, and demand fluctuations. By developing a robust forecasting model, companies can ensure they maintain optimal stock levels, reducing the costs associated with both overstock and stockouts. The insights gained from this model can be extended to other industries reliant on accurate demand prediction, such as manufacturing, e-commerce, and supply chain management.\n",
        "\n",
        "## **Strategies to Solve the Problem**\n",
        "1. **Feature Engineering**: A key part of this project involves creating meaningful features from historical sales data, such as monthly sales aggregates, lag-based features (e.g., previous month sales), and price trends. We will also explore combining supplemental data such as item categories and shop information to enrich our predictions.\n",
        "   \n",
        "2. **Handling Time Series Data**: Since the dataset consists of daily sales data from January 2013 to October 2015, we need to model temporal dependencies effectively. Strategies such as using **rolling windows** or **lag features** will help capture past trends, while features like the **date_block_num** will be used to track time progression.\n",
        "\n",
        "3. **Dealing with Data Sparsity**: In real-world retail settings, not every product is sold in every shop every month. This leads to sparse data, which can introduce noise into predictions. Techniques like **data aggregation** and **missing data imputation** will help mitigate these challenges.\n",
        "\n",
        "4. **Modeling Approach**: For this problem, we will experiment with both traditional machine learning models and advanced algorithms. Some potential models include:\n",
        "   - **Gradient Boosting Machines (GBM)**: XGBoost or LightGBM, which are well-suited for tabular data and can handle large datasets efficiently.\n",
        "   - **Neural Networks for Time Series**: Potentially exploring recurrent neural networks (RNN) or LSTMs to capture time dependencies in the sales data.\n",
        "   - **Ensembling**: Combining predictions from multiple models to create a more accurate and robust forecast.\n",
        "   \n",
        "\n",
        "5. **Evaluation Metric**: The competition uses Root Mean Squared Error (RMSE) as the evaluation metric, which penalizes larger errors more heavily. As the target values are clipped between 0 and 20, our model needs to focus on predicting values within this range accurately, avoiding extreme predictions.\n",
        "\n",
        "## **Roadmap to Success**\n",
        "- **Data Exploration and Preprocessing**: Initial exploratory data analysis (EDA) will help uncover key patterns in the data. Handling missing values, outliers, and understanding the distribution of target variables will form the foundation of the project.\n",
        "- **Feature Engineering**: Creating time-related features, capturing shop and item-level characteristics, and analyzing sales trends over time will be the core strategies to improve model performance.\n",
        "- **Modeling and Hyperparameter Tuning**: Experimenting with various machine learning algorithms, tuning hyperparameters, and leveraging cross-validation techniques will be crucial for model improvement.\n",
        "- **Final Submission**: We will predict the monthly sales for November 2015, ensuring the submission file follows the required format: `ID,item_cnt_month`.\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "flGpXXRQvIEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Function to load multiple CSV files\n",
        "def load_data(file_paths):\n",
        "    data = {}\n",
        "    for name, path in file_paths.items():\n",
        "        data[name] = pd.read_csv(path)\n",
        "    return data\n",
        "\n",
        "# Define file paths in a dictionary\n",
        "file_paths = {\n",
        "    'sales_data': '/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv',\n",
        "    'item_cat': '/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv',\n",
        "    'items': '/kaggle/input/competitive-data-science-predict-future-sales/items.csv',\n",
        "    'shops': '/kaggle/input/competitive-data-science-predict-future-sales/shops.csv',\n",
        "    'test':'/kaggle/input/competitive-data-science-predict-future-sales/test.csv'\n",
        "}\n",
        "\n",
        "# Load the data\n",
        "data = load_data(file_paths)\n",
        "\n",
        "# Access each dataset by its key\n",
        "sales_data = data['sales_data']\n",
        "item_categories = data['item_cat']\n",
        "items = data['items']\n",
        "shops = data['shops']\n",
        "test_data=data['test']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:18.532106Z",
          "iopub.execute_input": "2024-09-28T13:34:18.532542Z",
          "iopub.status.idle": "2024-09-28T13:34:20.404422Z",
          "shell.execute_reply.started": "2024-09-28T13:34:18.532497Z",
          "shell.execute_reply": "2024-09-28T13:34:20.403569Z"
        },
        "trusted": true,
        "id": "L15_iLQ6vIE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Basic information about datasets\n",
        "print(\"Sales Data Info:\\n\")\n",
        "print(sales_data.info())\n",
        "print(\"\\nTest Data Info:\\n\")\n",
        "print(test_data.info())\n",
        "print(\"\\nItems Info:\\n\")\n",
        "print(items.info())\n",
        "print(\"\\nItem Categories Info:\\n\")\n",
        "print(item_categories.info())\n",
        "print(\"\\nShops Info:\\n\")\n",
        "print(shops.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:20.406346Z",
          "iopub.execute_input": "2024-09-28T13:34:20.406686Z",
          "iopub.status.idle": "2024-09-28T13:34:20.435833Z",
          "shell.execute_reply.started": "2024-09-28T13:34:20.406651Z",
          "shell.execute_reply": "2024-09-28T13:34:20.43494Z"
        },
        "trusted": true,
        "id": "eKDuTiMnvIFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values in Sales Data:\\n\", sales_data.isnull().sum())\n",
        "print(\"\\nMissing Values in Test Data:\\n\", test_data.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:20.437032Z",
          "iopub.execute_input": "2024-09-28T13:34:20.437398Z",
          "iopub.status.idle": "2024-09-28T13:34:20.719195Z",
          "shell.execute_reply.started": "2024-09-28T13:34:20.43736Z",
          "shell.execute_reply": "2024-09-28T13:34:20.718303Z"
        },
        "trusted": true,
        "id": "ICDKYxh2vIFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Date parsing and feature extraction\n",
        "\n",
        "sales_data['date'] = pd.to_datetime(sales_data['date'], format='%d.%m.%Y')\n",
        "sales_data['year'] = sales_data['date'].dt.year\n",
        "sales_data['month'] = sales_data['date'].dt.month"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:20.721932Z",
          "iopub.execute_input": "2024-09-28T13:34:20.722292Z",
          "iopub.status.idle": "2024-09-28T13:34:21.351136Z",
          "shell.execute_reply.started": "2024-09-28T13:34:20.722255Z",
          "shell.execute_reply": "2024-09-28T13:34:21.350113Z"
        },
        "trusted": true,
        "id": "aNc2kXYTvIFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:21.352563Z",
          "iopub.execute_input": "2024-09-28T13:34:21.352958Z",
          "iopub.status.idle": "2024-09-28T13:34:21.365928Z",
          "shell.execute_reply.started": "2024-09-28T13:34:21.35291Z",
          "shell.execute_reply": "2024-09-28T13:34:21.365031Z"
        },
        "trusted": true,
        "id": "0uxf_TNKvIFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by 'date', 'shop_id', and 'item_id' to get the total number of items sold\n",
        "grouped_sales = sales_data.groupby(['date', 'shop_id', 'item_id']).agg({'item_cnt_day': 'sum'}).reset_index()\n",
        "\n",
        "# Renaming the 'item_cnt_day' column to 'total_items_sold' for clarity\n",
        "grouped_sales.rename(columns={'item_cnt_day': 'total_items_sold'}, inplace=True)\n",
        "\n",
        "# Display the result\n",
        "print(grouped_sales.head(10))  # Display the first few rows to check the result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:21.367288Z",
          "iopub.execute_input": "2024-09-28T13:34:21.367662Z",
          "iopub.status.idle": "2024-09-28T13:34:22.361893Z",
          "shell.execute_reply.started": "2024-09-28T13:34:21.367619Z",
          "shell.execute_reply": "2024-09-28T13:34:22.36097Z"
        },
        "trusted": true,
        "id": "Xz7wbs19vIFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Plot for Total Items Sold by Date\n",
        "\n",
        "This shows how the total number of items sold changes over time."
      ],
      "metadata": {
        "id": "lwlmCNLlvIFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Group by 'date' to get total items sold across all shops and items for each date\n",
        "datewise_sales = grouped_sales.groupby('date')['total_items_sold'].sum().reset_index()\n",
        "\n",
        "# Convert 'date' to datetime format for better plotting\n",
        "datewise_sales['date'] = pd.to_datetime(datewise_sales['date'], format='%d.%m.%Y')\n",
        "\n",
        "# Plot the total items sold over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x='date', y='total_items_sold', data=datewise_sales)\n",
        "plt.title('Total Items Sold Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Items Sold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:22.363253Z",
          "iopub.execute_input": "2024-09-28T13:34:22.363654Z",
          "iopub.status.idle": "2024-09-28T13:34:22.771874Z",
          "shell.execute_reply.started": "2024-09-28T13:34:22.363609Z",
          "shell.execute_reply": "2024-09-28T13:34:22.770959Z"
        },
        "trusted": true,
        "id": "y2mpa7UDvIFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar Plot for Total Items Sold by Shop\n",
        "\n",
        "This shows how many total items were sold in each shop."
      ],
      "metadata": {
        "id": "RggB11UHvIFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'shop_id' to get total items sold for each shop\n",
        "shopwise_sales = grouped_sales.groupby('shop_id')['total_items_sold'].sum().reset_index()\n",
        "\n",
        "# Plot total items sold per shop\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='shop_id', y='total_items_sold', data=shopwise_sales)\n",
        "plt.title('Total Items Sold per Shop')\n",
        "plt.xlabel('Shop ID')\n",
        "plt.ylabel('Total Items Sold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:22.773197Z",
          "iopub.execute_input": "2024-09-28T13:34:22.773581Z",
          "iopub.status.idle": "2024-09-28T13:34:23.435648Z",
          "shell.execute_reply.started": "2024-09-28T13:34:22.773536Z",
          "shell.execute_reply": "2024-09-28T13:34:23.434392Z"
        },
        "trusted": true,
        "id": "4Q6AEWMdvIFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of unique shop_ids\n",
        "num_shops = sales_data['shop_id'].nunique()\n",
        "\n",
        "# Display the result\n",
        "print(f'Total number of unique shops: {num_shops}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:23.437259Z",
          "iopub.execute_input": "2024-09-28T13:34:23.437618Z",
          "iopub.status.idle": "2024-09-28T13:34:23.462671Z",
          "shell.execute_reply.started": "2024-09-28T13:34:23.437569Z",
          "shell.execute_reply": "2024-09-28T13:34:23.461711Z"
        },
        "trusted": true,
        "id": "vrNyfGluvIFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monthly sales trend"
      ],
      "metadata": {
        "id": "IEkoIu1xvIFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sales = sales_data.groupby(['year', 'month']).agg({'item_cnt_day': 'sum'}).reset_index()\n",
        "monthly_sales['date'] = pd.to_datetime(monthly_sales[['year', 'month']].assign(day=1))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(monthly_sales['date'], monthly_sales['item_cnt_day'], marker='o')\n",
        "plt.title('Monthly Sales Trend (2013-2015)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:23.467913Z",
          "iopub.execute_input": "2024-09-28T13:34:23.468281Z",
          "iopub.status.idle": "2024-09-28T13:34:23.882877Z",
          "shell.execute_reply.started": "2024-09-28T13:34:23.468249Z",
          "shell.execute_reply": "2024-09-28T13:34:23.881912Z"
        },
        "trusted": true,
        "id": "nO7w5ssxvIFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 10 selling items"
      ],
      "metadata": {
        "id": "-Jcbv1KcvIFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_items = sales_data.groupby('item_id').agg({'item_cnt_day': 'sum'}).sort_values(by='item_cnt_day', ascending=False).head(10)\n",
        "top_items = top_items.merge(items[['item_id', 'item_name']], on='item_id')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='item_name', y='item_cnt_day', data=top_items)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Top 10 Selling Items')\n",
        "plt.xlabel('Item Name')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:23.884019Z",
          "iopub.execute_input": "2024-09-28T13:34:23.884323Z",
          "iopub.status.idle": "2024-09-28T13:34:24.329668Z",
          "shell.execute_reply.started": "2024-09-28T13:34:23.884289Z",
          "shell.execute_reply": "2024-09-28T13:34:24.328749Z"
        },
        "trusted": true,
        "id": "JOGTt7AnvIFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 10 selling shops"
      ],
      "metadata": {
        "id": "CevmiSOQvIFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_shops = sales_data.groupby('shop_id').agg({'item_cnt_day': 'sum'}).sort_values(by='item_cnt_day', ascending=False).head(10)\n",
        "top_shops = top_shops.merge(shops[['shop_id', 'shop_name']], on='shop_id')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='shop_id', y='item_cnt_day', data=top_shops)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Top 10 Shops by Sales')\n",
        "plt.xlabel('Shop ID')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:24.33078Z",
          "iopub.execute_input": "2024-09-28T13:34:24.33108Z",
          "iopub.status.idle": "2024-09-28T13:34:24.684623Z",
          "shell.execute_reply.started": "2024-09-28T13:34:24.331047Z",
          "shell.execute_reply": "2024-09-28T13:34:24.68356Z"
        },
        "trusted": true,
        "id": "Wwm_4QhovIFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:24.685715Z",
          "iopub.execute_input": "2024-09-28T13:34:24.686018Z",
          "iopub.status.idle": "2024-09-28T13:34:24.695291Z",
          "shell.execute_reply.started": "2024-09-28T13:34:24.685984Z",
          "shell.execute_reply": "2024-09-28T13:34:24.69442Z"
        },
        "trusted": true,
        "id": "svPfteI5vIFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshape the data to analyse Total Sales over time\n",
        "\n",
        "Lets see and analyze total sales shop-wise,item-wise over time. For that we need to reshape the data.The `pivot_table` function allows us to summarize and organize the sales data by transforming it into a more accessible format.\n",
        "\n",
        "By grouping the data based on `shop_id` and `item_id`, and distributing it across different months (`date_block_num`), we can easily observe sales trends for each product-shop combination over time. This pivot table helps us in visualizing the sales patterns and preparing the data for future time-series analysis and forecasting.\n",
        "\n",
        "The `fill_value=0` ensures that any missing values are replaced with `0`, indicating that no sales occurred for a specific product-shop combination during certain months. The `reset_index()` function is used to convert the pivoted data back into a standard DataFrame format with default integer indexing for easier manipulation in subsequent steps."
      ],
      "metadata": {
        "id": "l5ZbQK9ovIFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure shop_id and item_id are present in the pivot table\n",
        "dataset = sales_data.pivot_table(index=['shop_id', 'item_id'], values='item_cnt_day',\n",
        "                                 columns='date_block_num', fill_value=0, aggfunc='sum').reset_index()\n",
        "\n",
        "# Flatten the multi-level columns in the dataset\n",
        "dataset.columns = ['_'.join(map(str, col)) if isinstance(col, tuple) else col for col in dataset.columns]\n",
        "\n",
        "# Merge with test_data\n",
        "merged_data = pd.merge(test_data, dataset, on=['item_id', 'shop_id'], how='left')\n",
        "\n",
        "# Display the merged dataset\n",
        "print(merged_data.head())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:24.69633Z",
          "iopub.execute_input": "2024-09-28T13:34:24.696633Z",
          "iopub.status.idle": "2024-09-28T13:34:25.858481Z",
          "shell.execute_reply.started": "2024-09-28T13:34:24.696601Z",
          "shell.execute_reply": "2024-09-28T13:34:25.85753Z"
        },
        "trusted": true,
        "id": "6NVqBsD9vIFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of the Merge\n",
        "\n",
        "The reason for merging the test data with the dataset is to incorporate historical sales data from the training period into the test dataset. This allows the model to make predictions for each shop_id and item_id combination in the test data based on past sales patterns.\n",
        "\n",
        "### Key Points:\n",
        "\n",
        "* Left join ensures that all rows from test_data are preserved, even if thereâ€™s no corresponding historical data for the specific shop_id and item_id.\n",
        "\n",
        "* Historical features such as past sales from the dataset are now included in the test_data, making it ready for prediction.\n",
        "\n",
        "### Parameters used:\n",
        "\n",
        "* on=['item_id', 'shop_id']: This tells the merge() function to combine the two DataFrames based on the common columns item_id and shop_id.\n",
        "\n",
        "* how='left': This specifies a left join, meaning:\n",
        "\n",
        "    *     All rows from the test_data will be retained.\n",
        "\n",
        "    *     Only matching rows from dataset will be included. If there's no match for a particular item_id and shop_id in dataset, those values will be set to NaN.\n",
        "    \n",
        "**This ensures that your model is trained on historical data relevant to the combinations it needs to predict in the test set. The result is a more focused dataset that contains only the historical sales information necessary for making predictions for the specified shop_id and item_id pairs in the test data.**"
      ],
      "metadata": {
        "id": "BAqmKhktvIFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:25.859724Z",
          "iopub.execute_input": "2024-09-28T13:34:25.860057Z",
          "iopub.status.idle": "2024-09-28T13:34:25.888542Z",
          "shell.execute_reply.started": "2024-09-28T13:34:25.860021Z",
          "shell.execute_reply": "2024-09-28T13:34:25.887593Z"
        },
        "trusted": true,
        "id": "uZODTD3JvIFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.fillna(0,inplace=True)\n",
        "merged_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:25.88979Z",
          "iopub.execute_input": "2024-09-28T13:34:25.890102Z",
          "iopub.status.idle": "2024-09-28T13:34:26.004744Z",
          "shell.execute_reply.started": "2024-09-28T13:34:25.890068Z",
          "shell.execute_reply": "2024-09-28T13:34:26.003728Z"
        },
        "trusted": true,
        "id": "WQGsHG0svIFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.drop(['shop_id','item_id','ID'],axis=1,inplace=True)\n",
        "merged_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.00606Z",
          "iopub.execute_input": "2024-09-28T13:34:26.008556Z",
          "iopub.status.idle": "2024-09-28T13:34:26.049171Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.008492Z",
          "shell.execute_reply": "2024-09-28T13:34:26.048302Z"
        },
        "trusted": true,
        "id": "nTKO_sbVvIFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Drop These Columns:\n",
        "\n",
        "- **Redundancy**: Once the data is merged, the `shop_id`, `item_id`, and `ID` columns no longer add value to the model, as their purpose was primarily organizational or structural.\n",
        "  \n",
        "- **Focus on Predictive Features**: The goal is to focus on features that help in making predictions (such as historical sales, prices, or other aggregated features). Columns that don't contribute to the model's learning are removed to avoid clutter.\n",
        "  \n",
        "- **Model Efficiency**: By removing unnecessary columns, the dataset becomes cleaner, and this can improve model training efficiency and reduce memory usage.\n"
      ],
      "metadata": {
        "id": "tHG4lBGivIFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train=np.expand_dims(merged_data.values[:,:-1],axis=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.050304Z",
          "iopub.execute_input": "2024-09-28T13:34:26.050688Z",
          "iopub.status.idle": "2024-09-28T13:34:26.055749Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.050645Z",
          "shell.execute_reply": "2024-09-28T13:34:26.05476Z"
        },
        "trusted": true,
        "id": "IIY1UmgvvIFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*merged_data.values[:, :-1] selects all rows and all columns except the last one from the merged_data dataframe.*\n",
        "\n",
        "the date_block_num starts at 0, which represents January 2013, and each subsequent date_block_num increases by one month.\n",
        "\n",
        "Thus, to find out which month and year date_block_num = 33 corresponds to, you can calculate it like this:\n",
        "\n",
        "    * Month 0 = January 2013\n",
        "    * Month 33 = 34th month after January 2013.\n",
        "\n",
        "To calculate:\n",
        "\n",
        "    * 34 months from January 2013 = November 2015.\n",
        "\n",
        "**So, column 33 in merged_data corresponds to November 2015, for which we need to make the prediction.\n",
        "Column 33 is out Target column, hence removed that column from X_train.**"
      ],
      "metadata": {
        "id": "spR1Lb_ovIFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.057043Z",
          "iopub.execute_input": "2024-09-28T13:34:26.057405Z",
          "iopub.status.idle": "2024-09-28T13:34:26.069143Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.057373Z",
          "shell.execute_reply": "2024-09-28T13:34:26.068365Z"
        },
        "trusted": true,
        "id": "zVDSMTUcvIFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Use `np.expand_dims` for Training Data?\n",
        "\n",
        "The code `X_train = np.expand_dims(merged_data.values[:, :-1], axis=2)` is used to reshape the data into a format suitable for machine learning models, particularly those dealing with sequences, such as Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs). Let's break down why this transformation is necessary:\n",
        "\n",
        "#### 1. Reshaping the Input:\n",
        "- `merged_data.values[:, :-1]` selects all rows and columns except the last one from the `merged_data` dataframe. This helps extract the feature columns used for training while excluding the target variable (often the last column).\n",
        "  \n",
        "#### 2. Adding an Extra Dimension:\n",
        "- `np.expand_dims(..., axis=2)` introduces a new dimension at the third axis (`axis=2`). This operation transforms a 2D array (rows and columns) into a 3D array (rows, columns, and depth).\n",
        "\n",
        "#### 3. Why Add an Extra Dimension?\n",
        "- **Sequential/Time-Series Data**: Certain models (e.g., RNNs, LSTMs, CNNs) expect input data in a 3D format, where each \"depth\" layer corresponds to either a sequence step or a feature map. Expanding the dimension allows the model to interpret each feature vector as part of a sequence.\n",
        "- **Shape for Model Input**: Adding this extra dimension makes the data compatible with models that expect input in the format `(samples, timesteps, features)`. Without this adjustment, the model might not correctly interpret the structure of the input data.\n",
        "\n",
        "#### Summary:\n",
        "This transformation prepares the data for models requiring 3D input by adding an extra dimension, enabling the model to process the data correctly, especially for tasks like time-series forecasting or sequence modeling.\n"
      ],
      "metadata": {
        "id": "kNTqzYbOvIFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=merged_data.values[:,-1:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.070129Z",
          "iopub.execute_input": "2024-09-28T13:34:26.070415Z",
          "iopub.status.idle": "2024-09-28T13:34:26.077603Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.070384Z",
          "shell.execute_reply": "2024-09-28T13:34:26.076752Z"
        },
        "trusted": true,
        "id": "qlH_n-KLvIFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=np.expand_dims(merged_data.values[:,1:],axis = 2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.078653Z",
          "iopub.execute_input": "2024-09-28T13:34:26.079005Z",
          "iopub.status.idle": "2024-09-28T13:34:26.086288Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.078963Z",
          "shell.execute_reply": "2024-09-28T13:34:26.085396Z"
        },
        "trusted": true,
        "id": "PDN3V1xMvIFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics  import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv1D,MaxPooling1D\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM,RepeatVector,TimeDistributed,Flatten"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.087372Z",
          "iopub.execute_input": "2024-09-28T13:34:26.087659Z",
          "iopub.status.idle": "2024-09-28T13:34:26.096059Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.087627Z",
          "shell.execute_reply": "2024-09-28T13:34:26.095171Z"
        },
        "trusted": true,
        "id": "5XKZY-l0vIFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Initialize the model\n",
        "model_lstm = tf.keras.Sequential()\n",
        "\n",
        "# Add an Input layer to specify the input shape\n",
        "model_lstm.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# Add LSTM layer\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=64))\n",
        "\n",
        "# Add Dropout layer\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "# Add Dense layer\n",
        "model_lstm.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model_lstm.compile(loss='mse', optimizer='SGD', metrics=['mean_squared_error'])\n",
        "\n",
        "# Display the model summary\n",
        "model_lstm.summary()'''\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.097024Z",
          "iopub.execute_input": "2024-09-28T13:34:26.097332Z",
          "iopub.status.idle": "2024-09-28T13:34:26.107571Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.097301Z",
          "shell.execute_reply": "2024-09-28T13:34:26.106727Z"
        },
        "trusted": true,
        "id": "AQfaTulcvIFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.108602Z",
          "iopub.execute_input": "2024-09-28T13:34:26.108962Z",
          "iopub.status.idle": "2024-09-28T13:34:26.117643Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.108919Z",
          "shell.execute_reply": "2024-09-28T13:34:26.116847Z"
        },
        "trusted": true,
        "id": "NMcliraVvIFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''history_lstm=model_lstm.fit(X_train,y_train,batch_size=4096,epochs=20)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.11862Z",
          "iopub.execute_input": "2024-09-28T13:34:26.118874Z",
          "iopub.status.idle": "2024-09-28T13:34:26.128023Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.118845Z",
          "shell.execute_reply": "2024-09-28T13:34:26.127265Z"
        },
        "trusted": true,
        "id": "PcjE0P8PvIFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "plt.plot(history_lstm.history['loss'],color='b',label=\"Training Loss\")\n",
        "plt.legend(loc='best',shadow=True)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.12916Z",
          "iopub.execute_input": "2024-09-28T13:34:26.129465Z",
          "iopub.status.idle": "2024-09-28T13:34:26.138124Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.129435Z",
          "shell.execute_reply": "2024-09-28T13:34:26.137191Z"
        },
        "trusted": true,
        "id": "WQIjzX8UvIFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''submission_pfs=model_lstm.predict(X_test)\n",
        "submission_pfs=submission_pfs.clip(0,20)\n",
        "submission=pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n",
        "submission.to_csv('submission.csv',index=False)'''\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.139286Z",
          "iopub.execute_input": "2024-09-28T13:34:26.139566Z",
          "iopub.status.idle": "2024-09-28T13:34:26.147818Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.139535Z",
          "shell.execute_reply": "2024-09-28T13:34:26.147024Z"
        },
        "trusted": true,
        "id": "yzGKkO6UvIFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''final=pd.read_csv('submission.csv')\n",
        "final.head()'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.153101Z",
          "iopub.execute_input": "2024-09-28T13:34:26.153555Z",
          "iopub.status.idle": "2024-09-28T13:34:26.159287Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.153522Z",
          "shell.execute_reply": "2024-09-28T13:34:26.158447Z"
        },
        "trusted": true,
        "id": "AqRR8IhUvIFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Initialize the model\n",
        "model_lstm = tf.keras.Sequential()\n",
        "\n",
        "# Add an Input layer to specify the input shape\n",
        "model_lstm.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "# Add LSTM layer with 128 units\n",
        "model_lstm.add(tf.keras.layers.LSTM(units=128))\n",
        "\n",
        "# Add Dropout layer with a dropout rate of 0.2\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Add Dense layer for output\n",
        "model_lstm.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model with Adam optimizer and learning rate of 0.001\n",
        "model_lstm.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['mean_squared_error'])\n",
        "\n",
        "# Display the model summary\n",
        "model_lstm.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.160241Z",
          "iopub.execute_input": "2024-09-28T13:34:26.160544Z",
          "iopub.status.idle": "2024-09-28T13:34:26.222653Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.16049Z",
          "shell.execute_reply": "2024-09-28T13:34:26.221801Z"
        },
        "trusted": true,
        "id": "o9-ILTwDvIFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm=model_lstm.fit(X_train,y_train,batch_size=4096,epochs=20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:34:26.223727Z",
          "iopub.execute_input": "2024-09-28T13:34:26.224018Z",
          "iopub.status.idle": "2024-09-28T13:35:02.534977Z",
          "shell.execute_reply.started": "2024-09-28T13:34:26.223987Z",
          "shell.execute_reply": "2024-09-28T13:35:02.534188Z"
        },
        "trusted": true,
        "id": "AklEu4IfvIFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_lstm.history['loss'],color='b',label=\"Training Loss\")\n",
        "plt.legend(loc='best',shadow=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:02.536161Z",
          "iopub.execute_input": "2024-09-28T13:35:02.536481Z",
          "iopub.status.idle": "2024-09-28T13:35:02.760644Z",
          "shell.execute_reply.started": "2024-09-28T13:35:02.536448Z",
          "shell.execute_reply": "2024-09-28T13:35:02.759711Z"
        },
        "trusted": true,
        "id": "FcBSuPkNvIFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_pfs=model_lstm.predict(X_test)\n",
        "submission_pfs=submission_pfs.clip(0,20)\n",
        "submission=pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n",
        "submission.to_csv('submission.csv',index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:03.025908Z",
          "iopub.execute_input": "2024-09-28T13:35:03.026632Z",
          "iopub.status.idle": "2024-09-28T13:35:16.785083Z",
          "shell.execute_reply.started": "2024-09-28T13:35:03.026586Z",
          "shell.execute_reply": "2024-09-28T13:35:16.784027Z"
        },
        "trusted": true,
        "id": "I4y6YWNjvIFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning"
      ],
      "metadata": {
        "id": "akFHFkVfvIFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Prepare your data (make sure to replace these with your actual data)\n",
        "# X_train, y_train = ...\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'units': [32, 64, 128, 256],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
        "    'learning_rate': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Store the best model and lowest MSE\n",
        "best_model = None\n",
        "lowest_mse = float('inf')\n",
        "\n",
        "# Loop through all combinations of hyperparameters\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f'Testing parameters: {params}')\n",
        "\n",
        "    # Initialize the model\n",
        "    model_lstm = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model_lstm.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # LSTM layer with variable units\n",
        "    model_lstm.add(LSTM(units=params['units'], return_sequences=True))\n",
        "    model_lstm.add(Dropout(params['dropout_rate']))\n",
        "\n",
        "    # Add another LSTM layer\n",
        "    model_lstm.add(LSTM(units=params['units'] // 2))  # Half the units for the second layer\n",
        "    model_lstm.add(Dropout(params['dropout_rate']))\n",
        "\n",
        "    # Dense output layer\n",
        "    model_lstm.add(Dense(1))\n",
        "\n",
        "    # Compile the model with variable learning rate\n",
        "    model_lstm.compile(loss='mse', optimizer=Adam(learning_rate=params['learning_rate']), metrics=['mean_squared_error'])\n",
        "\n",
        "    # Train the model\n",
        "    model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = model_lstm.evaluate(X_train, y_train, verbose=0)[0]\n",
        "    print(f'MSE for parameters {params}: {mse}')\n",
        "\n",
        "    # Check if this model is the best one\n",
        "    if mse < lowest_mse:\n",
        "        lowest_mse = mse\n",
        "        best_model = model_lstm\n",
        "\n",
        "print(f'Best model parameters: {best_model.layers}')\n",
        "print(f'Lowest MSE achieved: {lowest_mse}')\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.786484Z",
          "iopub.execute_input": "2024-09-28T13:35:16.786875Z",
          "iopub.status.idle": "2024-09-28T13:35:16.795209Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.786831Z",
          "shell.execute_reply": "2024-09-28T13:35:16.794295Z"
        },
        "trusted": true,
        "id": "YYcXOkG4vIFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#2nd model Multilayer Perceptron\n",
        "adam=optimizers.Adam()\n",
        "\n",
        "model_mlp=tf.keras.Sequential()\n",
        "model_mlp.add(tf.keras.layers.Dense(100,activation='relu',input_dim=X_train.shape[1]))\n",
        "model_mlp.add(tf.keras.layers.Dropout(0.4))\n",
        "model_mlp.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model_mlp.compile(loss='mse',optimizer='adam',metrics=['mean_squared_error'])\n",
        "model_mlp.summary()'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.796571Z",
          "iopub.execute_input": "2024-09-28T13:35:16.797191Z",
          "iopub.status.idle": "2024-09-28T13:35:16.808952Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.797146Z",
          "shell.execute_reply": "2024-09-28T13:35:16.8079Z"
        },
        "trusted": true,
        "id": "hKRysFnOvIFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''history_mlp=model_mlp.fit(X_train,y_train,batch_size=4096,epochs=20)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.810338Z",
          "iopub.execute_input": "2024-09-28T13:35:16.81063Z",
          "iopub.status.idle": "2024-09-28T13:35:16.821684Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.810592Z",
          "shell.execute_reply": "2024-09-28T13:35:16.820885Z"
        },
        "trusted": true,
        "id": "G5y9i-vKvIFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''plt.plot(history_mlp.history['loss'],color='b',label='Training Loss')\n",
        "plt.legend(loc='best',shadow=True)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.822691Z",
          "iopub.execute_input": "2024-09-28T13:35:16.823052Z",
          "iopub.status.idle": "2024-09-28T13:35:16.832273Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.823008Z",
          "shell.execute_reply": "2024-09-28T13:35:16.83138Z"
        },
        "trusted": true,
        "id": "H4BbVJmlvIFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''submission_pfs=model_mlp.predict(X_test)\n",
        "submission_pfs=submission_pfs.clip(0,20)\n",
        "submission=pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n",
        "submission.to_csv('submission.csv',index=False)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.833345Z",
          "iopub.execute_input": "2024-09-28T13:35:16.833656Z",
          "iopub.status.idle": "2024-09-28T13:35:16.842595Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.833608Z",
          "shell.execute_reply": "2024-09-28T13:35:16.841669Z"
        },
        "trusted": true,
        "id": "mwveBSfMvIFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''final=pd.read_csv('submission.csv')\n",
        "final.head()'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.843716Z",
          "iopub.execute_input": "2024-09-28T13:35:16.843999Z",
          "iopub.status.idle": "2024-09-28T13:35:16.852462Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.843968Z",
          "shell.execute_reply": "2024-09-28T13:35:16.851732Z"
        },
        "trusted": true,
        "id": "8vMZ-rQBvIFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "4N21ubW9vIFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''adam=optimizers.Adam()\n",
        "model_cnn=tf.keras.Sequential()\n",
        "model_cnn.add(Conv1D(filters=64,kernel_size=2,activation='relu',input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(150,activation='relu'))\n",
        "model_cnn.add(Dense(1))\n",
        "model_cnn.compile(loss='mse',optimizer=adam)\n",
        "model_cnn.summary()'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.853604Z",
          "iopub.execute_input": "2024-09-28T13:35:16.853993Z",
          "iopub.status.idle": "2024-09-28T13:35:16.863071Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.853951Z",
          "shell.execute_reply": "2024-09-28T13:35:16.862207Z"
        },
        "trusted": true,
        "id": "R9mLBtnjvIFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''cnn_history=model_cnn.fit(X_train,y_train,epochs=20,verbose=2)\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.86419Z",
          "iopub.execute_input": "2024-09-28T13:35:16.864528Z",
          "iopub.status.idle": "2024-09-28T13:35:16.873098Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.864487Z",
          "shell.execute_reply": "2024-09-28T13:35:16.872283Z"
        },
        "trusted": true,
        "id": "e4G2bykAvIFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''plt.plot(cnn_history.history['loss'],color='b',label='Training Loss')\n",
        "plt.legend(loc='best',shadow=True)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.874177Z",
          "iopub.execute_input": "2024-09-28T13:35:16.874491Z",
          "iopub.status.idle": "2024-09-28T13:35:16.88222Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.874459Z",
          "shell.execute_reply": "2024-09-28T13:35:16.881379Z"
        },
        "trusted": true,
        "id": "WZx5rQ_vvIFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''submission_pfs=model_cnn.predict(X_test)\n",
        "submission_pfs=submission_pfs.clip(0,20)\n",
        "submission=pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n",
        "submission.to_csv('submission.csv',index=False)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T13:35:16.883292Z",
          "iopub.execute_input": "2024-09-28T13:35:16.883574Z",
          "iopub.status.idle": "2024-09-28T13:35:16.892589Z",
          "shell.execute_reply.started": "2024-09-28T13:35:16.883543Z",
          "shell.execute_reply": "2024-09-28T13:35:16.891738Z"
        },
        "trusted": true,
        "id": "l565xA52vIFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}